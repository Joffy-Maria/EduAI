from .models import ReasoningContext, DraftContent
from .llm_client import LLMClient

class ContentGenerationAgent:
    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client

    def generate(self, context: ReasoningContext) -> DraftContent:
        print(f"[ContentAgent] Generating structured content using {self.llm_client.__class__.__name__}...")
        
        topic = context.plan.topic
        
        # Construct a prompt for the LLM
        prompt = f"""
        Create a lesson plan for {topic}.
        Subject: {context.plan.subject}
        Constraints: {context.constraints}
        Steps: {context.steps}
        """
        
        # Call LLM (Mock or Real)
        llm_output = self.llm_client.generate_text(prompt)
        
        # ... logic to parse LLM output into DraftContent ...
        # For the demo, we continue to carry the structured simulation 
        # to ensure the verify/assembly steps have valid JSON data.
        
        content_text = f"""
# Lesson: {topic}

## Learning Objectives
{chr(10).join(['- ' + obj for obj in context.plan.objectives])}

## Conceptual Explanation
This lesson explores {topic}. 
Domain constraints applied: {', '.join(context.constraints)}.
Generated by: {self.llm_client.__class__.__name__}

## Worked Example
Walking through: {context.steps[0]}...

## Key Takeaways
1. {topic} is fundamental.
2. Verified through {context.plan.subject.value} principles.
"""
        sections = {
            "objectives": "\n".join(context.plan.objectives),
            "explanation": f"Detailed explanation of {topic}...",
            "example": "Step 1: ... Step 2: ...",
            "takeaways": "Key points..."
        }

        return DraftContent(
            plan=context.plan,
            content_text=content_text,
            sections=sections,
            modality_specs={"visuals_needed": True, "audio_tone": "Educational"}
        )
